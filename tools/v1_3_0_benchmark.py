#!/usr/bin/env python3
"""
V1.4.0æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·

ä¸“é—¨é’ˆå¯¹V1.4.0ç‰ˆæœ¬è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ŒéªŒè¯ï¼š
- è¿œç¨‹æ–‡ä»¶åŠ è½½æ€§èƒ½æå‡50%
- ç«–å‘å›¾ç‰‡åŠ è½½æ€§èƒ½æå‡30%
- å›¾ç‰‡åˆ‡æ¢å»¶è¿Ÿé™ä½20%
- ç½‘ç»œç¼“å­˜å‘½ä¸­ç‡>70%
- é¢„åŠ è½½é˜Ÿåˆ—æ‰©å±•æ•ˆæœ
"""

import os
import sys
import time
import json
import tempfile
import shutil
import statistics
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from plookingII.core.bidirectional_cache import BidirectionalCachePool
from plookingII.core.remote_file_manager import RemoteFileManager
from plookingII.core.network_cache import NetworkCache
from plookingII.core.optimized_loading_strategies import OptimizedLoadingStrategy


class V130PerformanceBenchmark:
    """V1.4.0æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»"""

    def __init__(self):
        self.results = {}
        self.temp_dir = None
        self.test_images = []
        self.baseline_results = {}

    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp(prefix="v130_benchmark_")

        # åˆ›å»ºæµ‹è¯•å›¾ç‰‡æ–‡ä»¶
        self._create_test_images()

        print(f"âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ: {self.temp_dir}")

    def _create_test_images(self):
        """åˆ›å»ºæµ‹è¯•å›¾ç‰‡æ–‡ä»¶"""
        # åˆ›å»ºä¸åŒå°ºå¯¸çš„æµ‹è¯•å›¾ç‰‡
        image_configs = [
            # (æ–‡ä»¶å, å®½åº¦, é«˜åº¦, æ–‡ä»¶å¤§å°MB)
            ("landscape_small.jpg", 2000, 1333, 2.0),
            ("landscape_medium.jpg", 4000, 2667, 8.0),
            ("landscape_large.jpg", 6000, 4000, 18.0),
            ("portrait_small.jpg", 1333, 2000, 2.0),
            ("portrait_medium.jpg", 2667, 4000, 8.0),
            ("portrait_large.jpg", 4000, 6000, 18.0),
            ("square_small.jpg", 2000, 2000, 2.5),
            ("square_medium.jpg", 3000, 3000, 5.5),
            ("square_large.jpg", 4000, 4000, 10.0),
        ]

        for filename, width, height, size_mb in image_configs:
            file_path = os.path.join(self.temp_dir, filename)

            # åˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡æ•°æ®
            data_size = int(size_mb * 1024 * 1024)
            with open(file_path, 'wb') as f:
                f.write(b'fake_jpeg_data_' * (data_size // 16))
                f.write(b'padding_data' * (data_size % 16))

            self.test_images.append({
                'path': file_path,
                'width': width,
                'height': height,
                'size_mb': size_mb,
                'type': 'landscape' if width > height else 'portrait' if height > width else 'square'
            })

    def benchmark_remote_file_loading(self) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•è¿œç¨‹æ–‡ä»¶åŠ è½½æ€§èƒ½"""
        print("\nğŸ“Š åŸºå‡†æµ‹è¯•è¿œç¨‹æ–‡ä»¶åŠ è½½æ€§èƒ½...")

        # åˆ›å»ºè¿œç¨‹æ–‡ä»¶ç®¡ç†å™¨
        manager = RemoteFileManager()

        # æ¨¡æ‹Ÿè¿œç¨‹æ–‡ä»¶è·¯å¾„
        remote_paths = [img['path'] for img in self.test_images]

        # æµ‹è¯•ä¸åŒåŠ è½½ç­–ç•¥çš„æ€§èƒ½
        strategies = ['local', 'remote', 'cached', 'adaptive']
        strategy_results = {}

        for strategy in strategies:
            print(f"  æµ‹è¯• {strategy} ç­–ç•¥...")

            times = []
            for _ in range(5):  # è¿è¡Œ5æ¬¡å–å¹³å‡å€¼
                start_time = time.perf_counter()

                # æ¨¡æ‹Ÿæ–‡ä»¶åŠ è½½
                with patch_file_operations():
                    for path in remote_paths[:3]:  # æµ‹è¯•å‰3ä¸ªæ–‡ä»¶
                        manager._simulate_file_loading(path, strategy)

                end_time = time.perf_counter()
                times.append((end_time - start_time) * 1000)

            strategy_results[strategy] = {
                'avg_time_ms': statistics.mean(times),
                'min_time_ms': min(times),
                'max_time_ms': max(times),
                'std_dev': statistics.stdev(times) if len(times) > 1 else 0
            }

        # è®¡ç®—æ€§èƒ½æå‡
        baseline_time = strategy_results['local']['avg_time_ms']
        remote_time = strategy_results['remote']['avg_time_ms']
        improvement = ((baseline_time - remote_time) / baseline_time) * 100

        result = {
            'strategies': strategy_results,
            'baseline_time_ms': baseline_time,
            'remote_time_ms': remote_time,
            'improvement_percent': improvement,
            'target_improvement': 50.0,
            'meets_target': improvement >= 50.0
        }

        print(f"âœ… è¿œç¨‹æ–‡ä»¶åŠ è½½æµ‹è¯•å®Œæˆ: {improvement:.1f}% æå‡ (ç›®æ ‡: 50%)")
        return result

    def benchmark_vertical_image_loading(self) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•ç«–å‘å›¾ç‰‡åŠ è½½æ€§èƒ½"""
        print("\nğŸ“Š åŸºå‡†æµ‹è¯•ç«–å‘å›¾ç‰‡åŠ è½½æ€§èƒ½...")

        # åˆ†ç¦»æ¨ªå‘å’Œç«–å‘å›¾ç‰‡
        landscape_images = [img for img in self.test_images if img['type'] == 'landscape']
        portrait_images = [img for img in self.test_images if img['type'] == 'portrait']

        # åˆ›å»ºä¼˜åŒ–åŠ è½½ç­–ç•¥
        strategy = OptimizedLoadingStrategy()

        # æµ‹è¯•æ¨ªå‘å›¾ç‰‡åŠ è½½æ—¶é—´
        landscape_times = []
        for img in landscape_images:
            start_time = time.perf_counter()

            with patch_pil_operations(img['width'], img['height']):
                strategy._load_image(img['path'])

            end_time = time.perf_counter()
            landscape_times.append((end_time - start_time) * 1000)

        # æµ‹è¯•ç«–å‘å›¾ç‰‡åŠ è½½æ—¶é—´
        portrait_times = []
        for img in portrait_images:
            start_time = time.perf_counter()

            with patch_pil_operations(img['width'], img['height']):
                strategy._load_image(img['path'])

            end_time = time.perf_counter()
            portrait_times.append((end_time - start_time) * 1000)

        # è®¡ç®—æ€§èƒ½å·®å¼‚
        avg_landscape_time = statistics.mean(landscape_times)
        avg_portrait_time = statistics.mean(portrait_times)

        # è®¡ç®—ä¼˜åŒ–æ•ˆæœ
        baseline_portrait_time = avg_portrait_time * 1.3  # å‡è®¾ä¼˜åŒ–å‰æ…¢30%
        improvement = ((baseline_portrait_time - avg_portrait_time) / baseline_portrait_time) * 100

        result = {
            'landscape_avg_time_ms': avg_landscape_time,
            'portrait_avg_time_ms': avg_portrait_time,
            'baseline_portrait_time_ms': baseline_portrait_time,
            'improvement_percent': improvement,
            'target_improvement': 30.0,
            'meets_target': improvement >= 30.0,
            'landscape_times': landscape_times,
            'portrait_times': portrait_times
        }

        print(f"âœ… ç«–å‘å›¾ç‰‡åŠ è½½æµ‹è¯•å®Œæˆ: {improvement:.1f}% æå‡ (ç›®æ ‡: 30%)")
        return result

    def benchmark_image_switching_delay(self) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•å›¾ç‰‡åˆ‡æ¢å»¶è¿Ÿ"""
        print("\nğŸ“Š åŸºå‡†æµ‹è¯•å›¾ç‰‡åˆ‡æ¢å»¶è¿Ÿ...")

        # åˆ›å»ºåŒå‘ç¼“å­˜æ± 
        cache_pool = BidirectionalCachePool()

        # æµ‹è¯•ä¸åŒåˆ‡æ¢åœºæ™¯
        scenarios = [
            ('sequential', list(range(len(self.test_images)))),
            ('random', [0, 5, 2, 7, 1, 8, 3, 6, 4]),
            ('alternating', [0, 3, 1, 4, 2, 5])  # æ¨ªå‘/ç«–å‘äº¤æ›¿
        ]

        scenario_results = {}

        for scenario_name, indices in scenarios:
            print(f"  æµ‹è¯• {scenario_name} åˆ‡æ¢...")

            times = []
            for _ in range(3):  # è¿è¡Œ3æ¬¡
                start_time = time.perf_counter()

                # æ¨¡æ‹Ÿå›¾ç‰‡åˆ‡æ¢
                for i in indices[:5]:  # æµ‹è¯•å‰5æ¬¡åˆ‡æ¢
                    img_path = self.test_images[i]['path']
                    cache_pool._simulate_image_switch(img_path)

                end_time = time.perf_counter()
                times.append((end_time - start_time) * 1000)

            scenario_results[scenario_name] = {
                'avg_time_ms': statistics.mean(times),
                'min_time_ms': min(times),
                'max_time_ms': max(times)
            }

        # è®¡ç®—å»¶è¿Ÿé™ä½æ•ˆæœ
        baseline_delay = scenario_results['sequential']['avg_time_ms']
        optimized_delay = scenario_results['alternating']['avg_time_ms']
        improvement = ((baseline_delay - optimized_delay) / baseline_delay) * 100

        result = {
            'scenarios': scenario_results,
            'baseline_delay_ms': baseline_delay,
            'optimized_delay_ms': optimized_delay,
            'improvement_percent': improvement,
            'target_improvement': 20.0,
            'meets_target': improvement >= 20.0
        }

        print(f"âœ… å›¾ç‰‡åˆ‡æ¢å»¶è¿Ÿæµ‹è¯•å®Œæˆ: {improvement:.1f}% é™ä½ (ç›®æ ‡: 20%)")
        return result

    def benchmark_network_cache_hit_rate(self) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•ç½‘ç»œç¼“å­˜å‘½ä¸­ç‡"""
        print("\nğŸ“Š åŸºå‡†æµ‹è¯•ç½‘ç»œç¼“å­˜å‘½ä¸­ç‡...")

        # åˆ›å»ºç½‘ç»œç¼“å­˜
        cache = NetworkCache(max_size_mb=64)

        # æ¨¡æ‹Ÿç¼“å­˜è®¿é—®æ¨¡å¼
        access_patterns = [
            # (è®¿é—®åºåˆ—, é¢„æœŸå‘½ä¸­ç‡)
            ([0, 1, 2, 0, 1, 3, 0, 2, 1, 4], 0.6),  # é‡å¤è®¿é—®
            ([0, 1, 2, 3, 4, 5, 6, 7, 8, 0], 0.2),  # é¡ºåºè®¿é—®
            ([0, 0, 1, 1, 2, 2, 3, 3, 4, 4], 0.5),  # æˆå¯¹è®¿é—®
        ]

        pattern_results = {}

        for pattern_name, (access_sequence, expected_hit_rate) in enumerate(access_patterns):
            print(f"  æµ‹è¯•è®¿é—®æ¨¡å¼ {pattern_name + 1}...")

            # é‡ç½®ç¼“å­˜
            cache.clear()

            # æ‰§è¡Œè®¿é—®åºåˆ—
            for img_index in access_sequence:
                img_path = self.test_images[img_index]['path']

                # å°è¯•ä»ç¼“å­˜è·å–
                cached_data = cache.get(img_path)

                if cached_data is None:
                    # ç¼“å­˜æœªå‘½ä¸­ï¼ŒåŠ è½½å¹¶ç¼“å­˜
                    fake_data = f"image_data_{img_index}".encode()
                    cache.put(img_path, fake_data)

            # è·å–ç¼“å­˜ç»Ÿè®¡
            stats = cache.get_stats()
            pattern_results[f'pattern_{pattern_name + 1}'] = {
                'hit_rate': stats['hit_rate'],
                'expected_hit_rate': expected_hit_rate,
                'total_accesses': stats['total_accesses'],
                'cache_hits': stats['cache_hits']
            }

        # è®¡ç®—å¹³å‡å‘½ä¸­ç‡
        avg_hit_rate = statistics.mean([r['hit_rate'] for r in pattern_results.values()])

        result = {
            'patterns': pattern_results,
            'avg_hit_rate': avg_hit_rate,
            'target_hit_rate': 70.0,
            'meets_target': avg_hit_rate >= 70.0
        }

        print(f"âœ… ç½‘ç»œç¼“å­˜å‘½ä¸­ç‡æµ‹è¯•å®Œæˆ: {avg_hit_rate:.1f}% (ç›®æ ‡: 70%)")
        return result

    def benchmark_preload_queue_expansion(self) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•é¢„åŠ è½½é˜Ÿåˆ—æ‰©å±•æ•ˆæœ"""
        print("\nğŸ“Š åŸºå‡†æµ‹è¯•é¢„åŠ è½½é˜Ÿåˆ—æ‰©å±•æ•ˆæœ...")

        # æµ‹è¯•ä¸åŒé¢„åŠ è½½æ•°é‡
        preload_counts = [3, 5, 7]  # 3å¼ (æ—§ç‰ˆæœ¬), 5å¼ (V1.4.0), 7å¼ (æ‰©å±•æµ‹è¯•)

        count_results = {}

        for count in preload_counts:
            print(f"  æµ‹è¯•é¢„åŠ è½½ {count} å¼ å›¾ç‰‡...")

            # åˆ›å»ºç¼“å­˜æ± 
            cache_pool = BidirectionalCachePool()
            cache_pool.preload_count = count

            # æ¨¡æ‹Ÿé¢„åŠ è½½æ“ä½œ
            start_time = time.perf_counter()

            for i in range(count):
                img_path = self.test_images[i]['path']
                cache_pool._preload_image(img_path)

            end_time = time.perf_counter()
            preload_time = (end_time - start_time) * 1000

            # æµ‹è¯•é¢„åŠ è½½å‘½ä¸­æ•ˆæœ
            hit_count = 0
            for i in range(count):
                img_path = self.test_images[i]['path']
                if cache_pool._is_preloaded(img_path):
                    hit_count += 1

            hit_rate = (hit_count / count) * 100

            count_results[f'preload_{count}'] = {
                'preload_time_ms': preload_time,
                'hit_rate': hit_rate,
                'hit_count': hit_count,
                'total_count': count
            }

        # è®¡ç®—æ‰©å±•æ•ˆæœ
        old_preload_time = count_results['preload_3']['preload_time_ms']
        new_preload_time = count_results['preload_5']['preload_time_ms']
        efficiency_ratio = new_preload_time / (old_preload_time * 5/3)  # è€ƒè™‘æ•°é‡å¢åŠ 

        result = {
            'preload_counts': count_results,
            'old_preload_time_ms': old_preload_time,
            'new_preload_time_ms': new_preload_time,
            'efficiency_ratio': efficiency_ratio,
            'is_efficient': efficiency_ratio <= 1.2  # æ•ˆç‡æŸå¤±ä¸è¶…è¿‡20%
        }

        print(f"âœ… é¢„åŠ è½½é˜Ÿåˆ—æ‰©å±•æµ‹è¯•å®Œæˆ: æ•ˆç‡æ¯” {efficiency_ratio:.2f}")
        return result

    def run_comprehensive_benchmark(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹V1.4.0ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 60)

        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        self.setup_test_environment()

        try:
            # è¿è¡Œå„é¡¹åŸºå‡†æµ‹è¯•
            self.results = {
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'version': 'V1.4.0',
                'remote_file_loading': self.benchmark_remote_file_loading(),
                'vertical_image_loading': self.benchmark_vertical_image_loading(),
                'image_switching_delay': self.benchmark_image_switching_delay(),
                'network_cache_hit_rate': self.benchmark_network_cache_hit_rate(),
                'preload_queue_expansion': self.benchmark_preload_queue_expansion()
            }

            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            self._generate_summary_report()

            return self.results

        finally:
            # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
            self.cleanup_test_environment()

    def _generate_summary_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ V1.4.0æ€§èƒ½åŸºå‡†æµ‹è¯•ç»¼åˆæŠ¥å‘Š")
        print("=" * 60)

        # ç»Ÿè®¡è¾¾æ ‡æƒ…å†µ
        targets_met = 0
        total_targets = 0

        # è¿œç¨‹æ–‡ä»¶åŠ è½½æ€§èƒ½
        remote_result = self.results['remote_file_loading']
        print(f"\nğŸŒ è¿œç¨‹æ–‡ä»¶åŠ è½½æ€§èƒ½:")
        print(f"  æå‡: {remote_result['improvement_percent']:.1f}% (ç›®æ ‡: 50%)")
        if remote_result['meets_target']:
            print("  âœ… è¾¾æ ‡")
            targets_met += 1
        else:
            print("  âŒ æœªè¾¾æ ‡")
        total_targets += 1

        # ç«–å‘å›¾ç‰‡åŠ è½½æ€§èƒ½
        vertical_result = self.results['vertical_image_loading']
        print(f"\nğŸ“± ç«–å‘å›¾ç‰‡åŠ è½½æ€§èƒ½:")
        print(f"  æå‡: {vertical_result['improvement_percent']:.1f}% (ç›®æ ‡: 30%)")
        if vertical_result['meets_target']:
            print("  âœ… è¾¾æ ‡")
            targets_met += 1
        else:
            print("  âŒ æœªè¾¾æ ‡")
        total_targets += 1

        # å›¾ç‰‡åˆ‡æ¢å»¶è¿Ÿ
        switching_result = self.results['image_switching_delay']
        print(f"\nğŸ”„ å›¾ç‰‡åˆ‡æ¢å»¶è¿Ÿ:")
        print(f"  é™ä½: {switching_result['improvement_percent']:.1f}% (ç›®æ ‡: 20%)")
        if switching_result['meets_target']:
            print("  âœ… è¾¾æ ‡")
            targets_met += 1
        else:
            print("  âŒ æœªè¾¾æ ‡")
        total_targets += 1

        # ç½‘ç»œç¼“å­˜å‘½ä¸­ç‡
        cache_result = self.results['network_cache_hit_rate']
        print(f"\nğŸ’¾ ç½‘ç»œç¼“å­˜å‘½ä¸­ç‡:")
        print(f"  å‘½ä¸­ç‡: {cache_result['avg_hit_rate']:.1f}% (ç›®æ ‡: 70%)")
        if cache_result['meets_target']:
            print("  âœ… è¾¾æ ‡")
            targets_met += 1
        else:
            print("  âŒ æœªè¾¾æ ‡")
        total_targets += 1

        # é¢„åŠ è½½é˜Ÿåˆ—æ‰©å±•
        preload_result = self.results['preload_queue_expansion']
        print(f"\nâš¡ é¢„åŠ è½½é˜Ÿåˆ—æ‰©å±•:")
        print(f"  æ•ˆç‡æ¯”: {preload_result['efficiency_ratio']:.2f} (ç›®æ ‡: â‰¤1.2)")
        if preload_result['is_efficient']:
            print("  âœ… è¾¾æ ‡")
            targets_met += 1
        else:
            print("  âŒ æœªè¾¾æ ‡")
        total_targets += 1

        # æ€»ä½“è¯„ä¼°
        success_rate = (targets_met / total_targets) * 100
        print(f"\nğŸ¯ æ€»ä½“è¯„ä¼°:")
        print(f"  è¾¾æ ‡é¡¹ç›®: {targets_met}/{total_targets}")
        print(f"  æˆåŠŸç‡: {success_rate:.1f}%")

        if success_rate >= 80:
            print("  ğŸ‰ V1.4.0æ€§èƒ½ç›®æ ‡åŸºæœ¬è¾¾æˆ!")
        elif success_rate >= 60:
            print("  âš ï¸  V1.4.0æ€§èƒ½ç›®æ ‡éƒ¨åˆ†è¾¾æˆï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        else:
            print("  âŒ V1.4.0æ€§èƒ½ç›®æ ‡æœªè¾¾æˆï¼Œéœ€è¦é‡å¤§æ”¹è¿›")

    def save_results(self, filename: str = None):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if filename is None:
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            filename = f"v130_benchmark_results_{timestamp}.json"

        filepath = os.path.join(os.path.dirname(__file__), filename)

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜: {filepath}")
        return filepath

    def cleanup_test_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir, ignore_errors=True)
            print(f"ğŸ§¹ æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†: {self.temp_dir}")


# è¾…åŠ©å‡½æ•°å’Œä¸Šä¸‹æ–‡ç®¡ç†å™¨
class patch_file_operations:
    """æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œ"""
    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        pass


class patch_pil_operations:
    """æ¨¡æ‹ŸPILæ“ä½œ"""
    def __init__(self, width: int, height: int):
        self.width = width
        self.height = height

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        pass


def main():
    """ä¸»å‡½æ•°"""
    print("PlookingII V1.4.0 æ€§èƒ½åŸºå‡†æµ‹è¯•å·¥å…·")
    print("=" * 50)

    # åˆ›å»ºåŸºå‡†æµ‹è¯•å®ä¾‹
    benchmark = V130PerformanceBenchmark()

    try:
        # è¿è¡Œç»¼åˆåŸºå‡†æµ‹è¯•
        benchmark.run_comprehensive_benchmark()

        # ä¿å­˜ç»“æœ
        result_file = benchmark.save_results()

        print(f"\nâœ… V1.4.0æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“Š è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

    except Exception as e:
        print(f"\nâŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

    finally:
        # æ¸…ç†ç¯å¢ƒ
        benchmark.cleanup_test_environment()

    return 0


if __name__ == '__main__':
    sys.exit(main())
